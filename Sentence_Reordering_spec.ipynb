{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElNaMbLnRdHR"
      },
      "source": [
        "# Sentence Reconstruction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXr4iGUGRms8"
      },
      "source": [
        "The purpose of this project is to take in input a sequence of words corresponding to a random permutation of a given english sentence, and reconstruct the original sentence.\n",
        "\n",
        "The otuput can be either produced in a single shot, or through an iterative (autoregressive) loop generating a single token at a time.\n",
        "\n",
        "\n",
        "CONSTRAINTS:\n",
        "* No pretrained model can be used.\n",
        "* The neural network models should have less the 20M parameters.\n",
        "* No postprocessing should be done (e.g. no beamsearch)\n",
        "* You cannot use additional training data.\n",
        "\n",
        "\n",
        "BONUS PARAMETERS:\n",
        "\n",
        "A bonus of 0-2 points will be attributed to incentivate the adoption of models with a low number of parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQ8k-L-WUK7l"
      },
      "source": [
        "# Dataset\n",
        "\n",
        "The dataset is composed by sentences taken from the generics_kb dataset of hugging face. We restricted the vocabolary to the 10K most frequent words, and only took sentences making use of this vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nJ02vehGYySk",
        "outputId": "e40e988a-dab7-4d6f-f44c-678273e9dba9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the dataset"
      ],
      "metadata": {
        "id": "807Wk-ir_bDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from keras.layers import TextVectorization\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "ds = load_dataset('generics_kb',trust_remote_code=True)['train']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WjtqA8TrHcS",
        "outputId": "236c477f-7981-454e-cfd1-a19118566134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter row with length greater than 8.\n"
      ],
      "metadata": {
        "id": "lAVLfsdc_ej5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds = ds.filter(lambda row: len(row[\"generic_sentence\"].split(\" \"))>8 )\n",
        "corpus = [ '<start> ' + row['generic_sentence'].replace(\",\",\" <comma>\") + ' <end>' for row in ds ]\n",
        "corpus = np.array(corpus)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "6ac9b8152bba473ab9c22d64f69173b9",
            "d2eb59a45c0e4068a7497bb3a31b188d",
            "ecdfb26b614b490fb8b3c14d606b78b8",
            "01e2428b016d4c6588e8a399ebbbc367",
            "4be629ac0cc444d7ba724e8e54cb68cd",
            "d7272b54af0b42cd91ae6e1f2a8c66b7",
            "ad458b17c52e43a98d9779245b172cb9",
            "c71e6fdef7b74d9285cc4843b0a4889f",
            "fead1879bbf1494592e40405ca9ab6fd",
            "d388b76907324629a8dcf22232fbe368",
            "cc49c1aa52814e8082b2897ef630c5db"
          ]
        },
        "id": "iznq8xGNt2Zr",
        "outputId": "562e6fca-fbe5-4474-ec0e-463ff964ede6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/1020868 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ac9b8152bba473ab9c22d64f69173b9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a tokenizer and Detokenizer"
      ],
      "metadata": {
        "id": "FyYpXLCF_ldR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=TextVectorization( max_tokens=10000, standardize=\"lower_and_strip_punctuation\", encoding=\"utf-8\",) #con il max prende le piu frequenti. ordina i token del vocab dal piu frequente al meno frequente\n",
        "tokenizer.adapt(corpus)\n",
        "\n",
        "class TextDetokenizer:\n",
        "    def __init__(self, vectorize_layer):\n",
        "        self.vectorize_layer = vectorize_layer\n",
        "        vocab = self.vectorize_layer.get_vocabulary()\n",
        "        self.index_to_word = {index: word for index, word in enumerate(vocab)}\n",
        "\n",
        "    def __detokenize_tokens(self, tokens):\n",
        "        def check_token(t):\n",
        "          if t == 3:\n",
        "            s=\"<start>\"\n",
        "          elif t ==2:\n",
        "            s=\"<end>\"\n",
        "          elif t ==7:\n",
        "            s=\"<comma>\"\n",
        "          else:\n",
        "            s=self.index_to_word.get(t, '[UNK]')\n",
        "          return s\n",
        "\n",
        "        return ' '.join([ check_token(token) for token in tokens if token != 0])\n",
        "\n",
        "    def __call__(self, batch_tokens):\n",
        "       return [self.__detokenize_tokens(tokens) for tokens in batch_tokens]\n",
        "\n",
        "\n",
        "\n",
        "detokenizer = TextDetokenizer( tokenizer )\n",
        "sentences = tokenizer( corpus ).numpy()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "T-bE2JpVbU9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove from corpus the sentences where any unknow word appears"
      ],
      "metadata": {
        "id": "lZ64sns1_pSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask = np.sum( (sentences==1) , axis=1) >= 1\n",
        "original_data = np.delete( sentences, mask , axis=0)"
      ],
      "metadata": {
        "id": "2LPQtryQz5wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYfOscVk7U0r",
        "outputId": "c4be30c6-4b39-4cdc-deb5-399e1409555b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(241236, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shuffle the sentences"
      ],
      "metadata": {
        "id": "5puiiQ2D_uxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, data, batch_size=32, shuffle=True):\n",
        "\n",
        "        self.data = data\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.data) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        data_batch = np.array([self.data[k] for k in indexes])\n",
        "        #cop of ordered sequences\n",
        "        result = np.copy(data_batch)\n",
        "        #shuffle only the relevant positions for each batch\n",
        "        for i in range(data_batch.shape[0]):\n",
        "          np.random.shuffle(data_batch[i,1:data_batch[i].argmin() - 1])\n",
        "\n",
        "        return data_batch , result\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(len(self.data))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)"
      ],
      "metadata": {
        "id": "1ZXLkWB6od0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator = DataGenerator(original_data)\n",
        "x, y = test_generator.__getitem__(1)"
      ],
      "metadata": {
        "id": "uNlq1Khx1oH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = detokenizer(x)\n",
        "y = detokenizer(y)\n",
        "\n",
        "for i in range(7):\n",
        "  print(\"original: \", y[i])\n",
        "  print(\"shuffled: \", x[i])\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qR5xwMOn4E88",
        "outputId": "7f7d4cc0-d3a6-4273-cd00-1e0ddb6087cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original:  <start> dirt is easier to remove after paper has dried <end>\n",
            "shuffled:  <start> paper dried dirt has easier to is remove after <end>\n",
            "\n",
            "\n",
            "original:  <start> women generally have more estrogens circulating in their blood than men <end>\n",
            "shuffled:  <start> men blood circulating their than generally women have estrogens more in <end>\n",
            "\n",
            "\n",
            "original:  <start> vesicles are more than a watery soup surrounded by a membrane <end>\n",
            "shuffled:  <start> than soup membrane vesicles a watery by are surrounded a more <end>\n",
            "\n",
            "\n",
            "original:  <start> record companies are like musical investment banks or venture capitalists <end>\n",
            "shuffled:  <start> are companies record or capitalists investment musical venture like banks <end>\n",
            "\n",
            "\n",
            "original:  <start> harvesting is the process of separating the worms from the compost <end>\n",
            "shuffled:  <start> worms the separating is of the harvesting the compost from process <end>\n",
            "\n",
            "\n",
            "original:  <start> countries have the right to use forests for their social and economic development needs <end>\n",
            "shuffled:  <start> countries development have and to forests for economic needs their use social right the <end>\n",
            "\n",
            "\n",
            "original:  <start> smoking can take several years off ones life by increasing the risk of lung and heart diseases <end>\n",
            "shuffled:  <start> by several take can life ones off increasing the risk and diseases heart of years smoking lung <end>\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "detokenizer(y)[0:7]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9Ukpam36V4d",
        "outputId": "883a7ca4-cb23-4c37-cc20-66a1bad13733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> insulation does <comma> however <comma> have an impact on winter heating load <end>',\n",
              " '<start> ores are chemical compounds of metal atoms coupled with other materials <end>',\n",
              " '<start> accounting continues to be one of the leading professions world wide <end>',\n",
              " '<start> surgery is one form of treatment if the ligament is completely torn <end>',\n",
              " '<start> biomedical engineering is one of the newest engineering disciplines <end>',\n",
              " '<start> salamanders live on all the continents except antarctica and australia <end>',\n",
              " '<start> children tend to eat better if they have a say in what they eat <end>']"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "original_data = [sen for sen in tokenizer.texts_to_sequences(corpus) if (len(sen) <= 32 and len(sen)>4 and not(1 in sen))]\n",
        "\n",
        "if dump:\n",
        "    with open('original.pickle', 'wb') as handle:\n",
        "        pickle.dump(original_data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "print (\"filtered sentences: \",len(original_data))\n",
        "\n",
        "sos = tokenizer.word_index['<start>']\n",
        "eos = tokenizer.word_index['<end>']\n",
        "\n",
        "tokenizer.word_index['<pad>'] = 0\n",
        "tokenizer.index_word[0] = '<pad>'\n",
        "\n"
      ],
      "metadata": {
        "id": "keMdCCHl1R4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fo8MazCGBTv3"
      },
      "source": [
        "# Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0NOkuO0CfPo"
      },
      "source": [
        "Let s be the source string and p your prediction. The quality of the results will be measured according to the following metric:\n",
        "\n",
        "1.  look for the longest substring w between s and p\n",
        "2.  compute |w|/max(|s|,|p|)\n",
        "\n",
        "If the match is exact, the score is 1.\n",
        "\n",
        "When computing the score, you should NOT consider the start and end tokens.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-aUrdlXDdVf"
      },
      "source": [
        "The longest common substring can be computed with the SequenceMatcher function of difflib, that allows a simple definition of our metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulpTRdrF_huh"
      },
      "outputs": [],
      "source": [
        "from difflib import SequenceMatcher\n",
        "\n",
        "def score(s,p):\n",
        "  match = SequenceMatcher(None, s, p).find_longest_match()\n",
        "  #print(match.size)\n",
        "  return (match.size/max(len(p),len(s))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RB2YfjXNExM-"
      },
      "source": [
        "Let's do an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h17C8bVjEwur"
      },
      "outputs": [],
      "source": [
        "original = \"at first henry wanted to be friends with the king of france\"\n",
        "generated = \"henry wanted to be friends with king of france at the first\"\n",
        "\n",
        "print(\"your score is \",score(original,generated))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BET8GqBvFugR"
      },
      "source": [
        "The score must be computed as an average of at least 3K random examples taken form the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fwo7xj4GBW1"
      },
      "source": [
        "# What to deliver"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6uITuxOGHfJ"
      },
      "source": [
        "You are supposed to deliver a single notebook, suitably commented.\n",
        "The notebook should describe a single model, although you may briefly discuss additional attempts you did.\n",
        "\n",
        "The notebook should contain a full trace of the training.\n",
        "Weights should be made available on request.\n",
        "\n",
        "You must also give a clear assesment of the performance of the model, computed with the metric that has been given to you.\n",
        "\n",
        "# Good work!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6ac9b8152bba473ab9c22d64f69173b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2eb59a45c0e4068a7497bb3a31b188d",
              "IPY_MODEL_ecdfb26b614b490fb8b3c14d606b78b8",
              "IPY_MODEL_01e2428b016d4c6588e8a399ebbbc367"
            ],
            "layout": "IPY_MODEL_4be629ac0cc444d7ba724e8e54cb68cd"
          }
        },
        "d2eb59a45c0e4068a7497bb3a31b188d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7272b54af0b42cd91ae6e1f2a8c66b7",
            "placeholder": "​",
            "style": "IPY_MODEL_ad458b17c52e43a98d9779245b172cb9",
            "value": "Filter: 100%"
          }
        },
        "ecdfb26b614b490fb8b3c14d606b78b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c71e6fdef7b74d9285cc4843b0a4889f",
            "max": 1020868,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fead1879bbf1494592e40405ca9ab6fd",
            "value": 1020868
          }
        },
        "01e2428b016d4c6588e8a399ebbbc367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d388b76907324629a8dcf22232fbe368",
            "placeholder": "​",
            "style": "IPY_MODEL_cc49c1aa52814e8082b2897ef630c5db",
            "value": " 1020868/1020868 [00:25&lt;00:00, 32940.36 examples/s]"
          }
        },
        "4be629ac0cc444d7ba724e8e54cb68cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7272b54af0b42cd91ae6e1f2a8c66b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad458b17c52e43a98d9779245b172cb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c71e6fdef7b74d9285cc4843b0a4889f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fead1879bbf1494592e40405ca9ab6fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d388b76907324629a8dcf22232fbe368": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc49c1aa52814e8082b2897ef630c5db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}